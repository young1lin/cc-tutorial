# ============================================
# 00 - Basic Function Calling - çº¯ HTTP å®ç°
# ============================================
# è¯´æ˜ï¼šä½¿ç”¨ httpx ç›´æ¥è°ƒç”¨ APIï¼Œå±•ç¤º Function Calling åº•å±‚åŸç†
# ç‰¹ç‚¹ï¼š
#   - ä¸ä¾èµ– SDKï¼Œçº¯ HTTP è¯·æ±‚
#   - æµå¼å’Œéæµå¼ä¸¤ç§æ¨¡å¼
#   - è‡ªåŠ¨å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨å¾ªç¯
# ä½¿ç”¨ï¼š
#   uv run python 00_basic_function_calling.py 1
#   uv run python 00_basic_function_calling.py 1 -m ds   # DeepSeek
# ============================================

import argparse
import json
import os

import httpx
from dotenv import load_dotenv

from config import print_section, print_box_start, print_box_end, GRAY, RESET
from tools import TOOL_DEFINITIONS, execute_tool

load_dotenv()

# ============================================
# æ¨¡å‹é…ç½®
# ============================================

MODEL_CONFIGS = {
    "glm": {
        "base_url": "https://open.bigmodel.cn/api/coding/paas/v4/chat/completions",
        "api_key": os.getenv("GLM_API_KEY"),
        "model": "GLM-4-flash",
    },
    "glm-4.7": {
        "base_url": "https://open.bigmodel.cn/api/coding/paas/v4/chat/completions",
        "api_key": os.getenv("GLM_API_KEY"),
        "model": "GLM-4.7",
    },
    "deepseek": {
        "base_url": "https://api.deepseek.com/chat/completions",
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "model": "deepseek-chat",
    },
}

MODEL_ALIASES = {
    "glm": "glm",
    "glm4.7": "glm-4.7",
    "ds": "deepseek",
    "deepseek": "deepseek",
}

DEFAULT_MODEL = "glm-4.7"


# ============================================
# å·¥å…·è°ƒç”¨è¾“å‡º
# ============================================


def print_tool_call(func_name: str, func_args: dict, result: str, is_last: bool = False):
    """æ‰“å°å·¥å…·è°ƒç”¨ç»“æœ"""
    args_str = json.dumps(func_args, ensure_ascii=False)
    if len(result) > 100:
        result_preview = result[:97] + "..."
    else:
        result_preview = result
    print(f"â”‚   ğŸ“¥ è¾“å…¥: {func_name}({args_str})")
    print(f"â”‚   ğŸ“¤ è¾“å‡º: {result_preview}")
    if not is_last:
        print("â”‚")


# ============================================
# éæµå¼ Function Calling
# ============================================


def chat_non_streaming(
    messages: list[dict],
    model_config: dict,
    tools: list[dict] | None = None,
    max_iterations: int = 5,
) -> str:
    """éæµå¼ Function Calling å®ç°"""
    user_msg = next((m["content"] for m in messages if m["role"] == "user"), None)
    if user_msg:
        print_box_start("ğŸ“¥ ç”¨æˆ·è¾“å…¥")
        print(f"â”‚ {user_msg}")
        print_box_end()

    base_url = model_config["base_url"]
    api_key = model_config["api_key"]
    model = model_config["model"]

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }

    current_messages = messages.copy()
    iteration = 0

    while iteration < max_iterations:
        iteration += 1
        print(f"ğŸ”„ è°ƒç”¨ {model}...")

        payload = {
            "model": model,
            "messages": current_messages,
            "stream": False,
            "temperature": 0,
        }

        if tools:
            payload["tools"] = tools

        with httpx.Client(timeout=60.0) as client:
            response = client.post(base_url, headers=headers, json=payload)

        if response.status_code != 200:
            return f"API é”™è¯¯ï¼š{response.status_code} - {response.text}"

        data = response.json()
        choice = data["choices"][0]
        message = choice["message"]

        # æ‰“å°æ¨ç†å†…å®¹ï¼ˆç°è‰²ï¼‰
        if "reasoning_content" in message and message["reasoning_content"]:
            print(f"{GRAY}{message['reasoning_content']}{RESET}\n")

        # æ‰“å°å›å¤å†…å®¹
        if "content" in message and message["content"]:
            print(message["content"])

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        tool_calls = message.get("tool_calls")

        if tool_calls:
            current_messages.append(message)

            print_box_start(f"ğŸ”§ å·¥å…·è°ƒç”¨ #{iteration} ({len(tool_calls)}ä¸ª)")

            for i, tool_call in enumerate(tool_calls, 1):
                tool_call_id = tool_call["id"]
                func_name = tool_call["function"]["name"]
                func_args = json.loads(tool_call["function"]["arguments"])

                tool_result = execute_tool(func_name, func_args)
                print_tool_call(func_name, func_args, tool_result, is_last=(i == len(tool_calls)))

                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": tool_result,
                })
            print_box_end()
        else:
            return message.get("content", "")

    return "é”™è¯¯ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°"


# ============================================
# æµå¼ Function Calling
# ============================================


def chat_streaming(
    messages: list[dict],
    model_config: dict,
    tools: list[dict] | None = None,
    max_iterations: int = 5,
) -> str:
    """æµå¼ Function Calling å®ç°"""
    user_msg = next((m["content"] for m in messages if m["role"] == "user"), None)
    if user_msg:
        print_box_start("ğŸ“¥ ç”¨æˆ·è¾“å…¥")
        print(f"â”‚ {user_msg}")
        print_box_end()

    base_url = model_config["base_url"]
    api_key = model_config["api_key"]
    model = model_config["model"]

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }

    current_messages = messages.copy()
    iteration = 0

    while iteration < max_iterations:
        iteration += 1
        print(f"ğŸ”„ è°ƒç”¨ {model}...")

        payload = {
            "model": model,
            "messages": current_messages,
            "stream": True,
            "temperature": 0,
        }

        if tools:
            payload["tools"] = tools

        # æ”¶é›†æµå¼å“åº”
        collected_content = ""
        collected_reasoning = ""
        collected_tool_calls: dict[int, dict] = {}
        in_reasoning = False

        with httpx.Client(timeout=60.0) as client:
            with client.stream("POST", base_url, headers=headers, json=payload) as response:
                if response.status_code != 200:
                    return f"API é”™è¯¯ï¼š{response.status_code}"

                for line in response.iter_lines():
                    if not line or line == "data: [DONE]":
                        continue

                    if line.startswith("data: "):
                        try:
                            chunk_data = json.loads(line[6:])
                            delta = chunk_data["choices"][0].get("delta", {})

                            # æ”¶é›† reasoning_contentï¼ˆç°è‰²ï¼‰
                            if "reasoning_content" in delta and delta["reasoning_content"]:
                                reasoning_chunk = delta["reasoning_content"]
                                collected_reasoning += reasoning_chunk
                                if not in_reasoning:
                                    print(GRAY, end="", flush=True)
                                    in_reasoning = True
                                print(reasoning_chunk, end="", flush=True)

                            # æ”¶é›† content
                            if "content" in delta and delta["content"]:
                                if in_reasoning:
                                    print(RESET)
                                    in_reasoning = False
                                content_chunk = delta["content"]
                                collected_content += content_chunk
                                print(content_chunk, end="", flush=True)

                            # æ”¶é›† tool_calls
                            if "tool_calls" in delta:
                                for tool_call_delta in delta["tool_calls"]:
                                    idx = tool_call_delta.get("index", 0)

                                    if idx not in collected_tool_calls:
                                        collected_tool_calls[idx] = {
                                            "id": "",
                                            "type": "function",
                                            "function": {"name": "", "arguments": ""},
                                        }

                                    if "id" in tool_call_delta:
                                        collected_tool_calls[idx]["id"] = tool_call_delta["id"]

                                    if "function" in tool_call_delta:
                                        func_delta = tool_call_delta["function"]
                                        if "name" in func_delta:
                                            collected_tool_calls[idx]["function"]["name"] = func_delta["name"]
                                        if "arguments" in func_delta:
                                            collected_tool_calls[idx]["function"]["arguments"] += func_delta["arguments"]

                        except json.JSONDecodeError:
                            continue

        # ç¡®ä¿é¢œè‰²é‡ç½®
        if in_reasoning:
            print(RESET, end="", flush=True)
        print()

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if collected_tool_calls:
            tool_calls_list = list(collected_tool_calls.values())

            assistant_message: dict = {"role": "assistant"}
            if collected_content:
                assistant_message["content"] = collected_content
            assistant_message["tool_calls"] = tool_calls_list
            current_messages.append(assistant_message)

            print_box_start(f"ğŸ”§ å·¥å…·è°ƒç”¨ #{iteration} ({len(tool_calls_list)}ä¸ª)")

            for i, tool_call in enumerate(tool_calls_list, 1):
                tool_call_id = tool_call["id"]
                func_name = tool_call["function"]["name"]
                func_args = json.loads(tool_call["function"]["arguments"])

                tool_result = execute_tool(func_name, func_args)
                print_tool_call(func_name, func_args, tool_result, is_last=(i == len(tool_calls_list)))

                current_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": tool_result,
                })
            print_box_end()
        else:
            return collected_content

    return "é”™è¯¯ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°"


# ============================================
# æ¼”ç¤ºåœºæ™¯
# ============================================

DEMOS = {
    "1": {"name": "éæµå¼æ¨¡å¼", "question": "è¯·å¸®æˆ‘è®¡ç®—ï¼š(123 + 456) * 789 / 10ï¼Œç„¶åå‘Šè¯‰æˆ‘ç°åœ¨å‡ ç‚¹äº†ã€‚", "stream": False},
    "2": {"name": "æµå¼æ¨¡å¼", "question": "è¯·å¸®æˆ‘è®¡ç®—ï¼š(123 + 456) * 789 / 10ï¼Œç„¶åå‘Šè¯‰æˆ‘ç°åœ¨å‡ ç‚¹äº†ã€‚", "stream": True},
}


def print_help():
    print("=" * 60)
    print("00 - Basic Function Calling - çº¯ HTTP å®ç°")
    print("=" * 60)
    print()
    print("ç”¨æ³•: uv run python 00_basic_function_calling.py <demo_id> [-m <model>]")
    print()
    print("å¯ç”¨çš„åœºæ™¯:")
    for demo_id, demo in DEMOS.items():
        print(f"  {demo_id}. {demo['name']}")
    print()
    print("æ”¯æŒçš„æ¨¡å‹ (-m):")
    print("  - glm / glm4.7: GLM-4.7 (é»˜è®¤)")
    print("  - ds / deepseek: DeepSeek Chat")
    print()
    print("ç¤ºä¾‹:")
    print("  uv run python 00_basic_function_calling.py 1           # éæµå¼")
    print("  uv run python 00_basic_function_calling.py 2           # æµå¼")
    print("  uv run python 00_basic_function_calling.py 2 -m ds     # DeepSeek")
    print()


def main():
    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument("demo_id", nargs="?", default=None)
    parser.add_argument("-m", "--model", default="glm-4.7")
    parser.add_argument("-h", "--help", action="store_true")

    args = parser.parse_args()

    if args.help or args.demo_id is None:
        print_help()
        return

    if args.demo_id not in DEMOS:
        print(f"âŒ æœªçŸ¥çš„åœºæ™¯ ID: {args.demo_id}")
        print_help()
        return

    model_key = args.model.lower()
    model_name = MODEL_ALIASES.get(model_key, DEFAULT_MODEL)
    model_config = MODEL_CONFIGS.get(model_name, MODEL_CONFIGS[DEFAULT_MODEL])

    demo = DEMOS[args.demo_id]
    print_section(f"ğŸ“Œ {demo['name']} [{model_name}]")

    messages = [{"role": "user", "content": demo["question"]}]

    if demo["stream"]:
        chat_streaming(messages, model_config=model_config, tools=TOOL_DEFINITIONS)
    else:
        result = chat_non_streaming(messages, model_config=model_config, tools=TOOL_DEFINITIONS)
        print(f"\nğŸ¤– æœ€ç»ˆå“åº”:")
        print("-" * 40)
        print(result)

    print("\n" + "-" * 60)
    print("âœ… å®Œæˆ")
    print("-" * 60)


if __name__ == "__main__":
    main()
