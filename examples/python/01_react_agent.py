# ============================================
# 01 - ReAct Agent - çº¯æ–‡æœ¬ ReAct æ¨¡å¼
# ============================================
# è¯´æ˜ï¼šåŸºäº LangChain hwchase17/react æç¤ºè¯çš„çº¯æ–‡æœ¬ ReAct å®ç°
# ç‰¹ç‚¹ï¼š
#   - ä¸ä½¿ç”¨ Function Callingï¼Œçº¯æ–‡æœ¬è§£æ
#   - æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ª Action
#   - ä¸¥æ ¼çš„ Thought â†’ Action â†’ Observation å¾ªç¯
# ä½¿ç”¨ï¼š
#   uv run python 01_react_agent.py 1
#   uv run python 01_react_agent.py 1 -m ds      # DeepSeek
#   uv run python 01_react_agent.py 1 -m glm     # GLM-4-flash
# ============================================

import json
import logging
import os
import re
import sys
import argparse
from typing import Any

from dotenv import load_dotenv

# ============================================
# è°ƒè¯•æ—¥å¿—é…ç½®
# ============================================
logging.basicConfig(
    filename='react_debug.log',
    level=logging.DEBUG,
    format='%(asctime)s\n%(message)s\n' + '='*60
)

from config import (
    get_client,
    DEFAULT_PROVIDER,
    print_section,
    print_box_start,
    print_box_end,
    CYAN,
    GREEN,
    YELLOW,
    GRAY,
    RESET,
)
from tools import TOOL_DEFINITIONS, TOOL_IMPLEMENTATIONS, execute_tool
from datetime import datetime

load_dotenv()

# ============================================
# æ¨¡å‹åˆ«åæ˜ å°„
# ============================================

MODEL_ALIASES = {
    "glm": "glm-4-flash",
    "glm4": "glm-4-flash",
    "glm-4-flash": "glm-4-flash",
    "glm4.7": "glm-4.7",
    "glm-4.7": "glm-4.7",
    "glm5": "glm-5",
    "glm-5": "glm-5",
    "ds": "deepseek",
    "deepseek": "deepseek",
    "step": "stepfun",
    "stepfun": "stepfun",
}


# ============================================
# ReAct æç¤ºè¯
# ============================================

# System Prompt - å®Œæ•´çš„ ReAct æŒ‡ä»¤ï¼ˆå·¥å…· + æ ¼å¼ï¼‰
REACT_SYSTEM_PROMPT = """Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action as JSON
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!"""


def format_tools_for_prompt() -> tuple[str, str]:
    """æ ¼å¼åŒ–å·¥å…·æè¿°å’Œå·¥å…·ååˆ—è¡¨"""
    tool_descriptions = []
    tool_names = []
    for info in TOOL_DEFINITIONS:
        func = info["function"]
        params = ", ".join(
            f"{k}" for k in func["parameters"].get("properties", {}).keys()
        )
        tool_descriptions.append(f"{func['name']}({params}): {func['description']}")
        tool_names.append(func["name"])
    return "\n".join(tool_descriptions), ", ".join(tool_names)


# ============================================
# ReAct Agent
# ============================================


class ReActAgent:
    """ReAct Agent - æ–‡æœ¬è§£ææ¨¡å¼"""

    def __init__(self, provider: str = DEFAULT_PROVIDER):
        self.client, self.model = get_client(provider)
        self.provider = provider
        self.max_iterations = 10
        self.logger = logging.getLogger(__name__)

    def _parse_action(self, text: str) -> tuple[str | None, dict | None]:
        """è§£æ Action å’Œ Action Input - å‚è€ƒ LangChain å®ç°

        LangChain ä½¿ç”¨ç®€å•çš„æ­£åˆ™ï¼Œç”¨ \\n ä½œä¸ºåˆ†éš”ç¬¦ï¼Œä¸ä¾èµ–é¢„æµ‹æ¨¡å¼
        """
        # å…ˆæ£€æŸ¥ Final Answer
        if "Final Answer:" in text:
            return None, None  # è®© _parse_final_answer å¤„ç†

        # LangChain é£æ ¼çš„æ­£åˆ™ï¼šç®€å•ç›´æ¥ï¼Œç”¨ \n åˆ†éš”
        match = re.search(r"Action\s*:\s*(\w+)\s*\n\s*Action Input\s*:\s*(.+)", text, re.DOTALL)

        if not match:
            return None, None

        action = match.group(1).strip()
        action_input_str = match.group(2).strip()

        # è§£æ action_input
        action_input = self._parse_action_input(action_input_str)

        return action, action_input

    def _parse_action_input(self, raw_input: str) -> dict[str, Any]:
        """è§£æ Action Inputï¼Œæ”¯æŒ JSON å’Œ key="value" ä¸¤ç§æ ¼å¼"""
        raw_input = raw_input.strip()

        if raw_input.startswith("{"):
            try:
                cleaned = raw_input.replace("\n", "").replace("\r", "")
                return json.loads(cleaned)
            except json.JSONDecodeError:
                pass

        result = {}
        pattern = r'(\w+)\s*=\s*["\']([^"\']*)["\']'
        matches = re.findall(pattern, raw_input)
        for key, value in matches:
            result[key] = value

        if not result:
            pattern = r"(\w+)\s*=\s*(\S+)"
            matches = re.findall(pattern, raw_input)
            for key, value in matches:
                value = value.rstrip(",;")
                result[key] = value

        return result

    def _parse_final_answer(self, text: str) -> str | None:
        """è§£æ Final Answer"""
        match = re.search(r"Final Answer:\s*", text)
        if match:
            return text[match.end() :].strip()
        return None

    def _extract_thought(self, text: str) -> str:
        """æå–æœ€åä¸€ä¸ª Thought"""
        matches = list(
            re.finditer(
                r"Thought:\s*(.+?)(?=\n\s*(?:Action|Final Answer|Thought:)|$)",
                text,
                re.DOTALL,
            )
        )
        if matches:
            return matches[-1].group(1).strip()
        return ""

    def run(self, question: str, stream: bool = False) -> str:
        """æ‰§è¡Œ ReAct å¾ªç¯"""
        tools_desc, tool_names = format_tools_for_prompt()

        # æ„å»ºå›ºå®šçš„ system prompt
        system_prompt = REACT_SYSTEM_PROMPT.format(
            tools=tools_desc,
            tool_names=tool_names,
        )

        # æ‰“å° system prompt
        print_box_start("ğŸ¤– System Prompt")
        for line in system_prompt.split('\n'):
            print(f"â”‚ {line}")
        print_box_end()

        # æ‰“å°ç”¨æˆ·é—®é¢˜
        print_box_start("ğŸ‘¤ User")
        print(f"â”‚ {question}")
        print_box_end()

        # åˆå§‹åŒ– messages
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Question: {question}"},
        ]

        for iteration in range(1, self.max_iterations + 1):
            print(f"\n{CYAN}ğŸ”„ ç¬¬ {iteration} è½®{RESET}")

            # è°ƒè¯•æ—¥å¿—
            self.logger.debug(f"=== ç¬¬ {iteration} è½® ===")
            self.logger.debug(f"MESSAGES:\n{json.dumps(messages, ensure_ascii=False, indent=2)}")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0,
                stream=stream,
                stop=["\nObservation:", "\nObservation"],
            )

            if stream:
                output = self._handle_streaming(response)
            else:
                output = response.choices[0].message.content

            # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•åŸå§‹è¾“å‡º
            self.logger.debug(f"RAW OUTPUT (repr): {repr(output)}")

            # æ¸…ç†è¾“å‡ºæœ«å°¾å¯èƒ½çš„éƒ¨åˆ† stop sequence æ®‹ç•™
            # åŒ¹é…ï¼š\nObservation:ã€\nObservationã€\nObservã€\nObserã€\nObseã€\nObsã€\nOb ç­‰
            output_cleaned = re.sub(r'\n?Ob(?:s(?:e(?:r(?:v(?:a(?:t(?:i(?:o(?:n?)?)?)?)?)?)?)?)?)?(?::)?$', '', output).strip()
            if output_cleaned != output:
                self.logger.debug(f"CLEANED OUTPUT (removed partial stop): {repr(output_cleaned)}")

            action, action_input = self._parse_action(output_cleaned)

            # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•è§£æç»“æœ
            self.logger.debug(f"PARSED: action={action}, action_input={action_input}")

            if not action:
                final_answer = self._parse_final_answer(output_cleaned)
                if final_answer and iteration > 1:
                    print(f"\n{GREEN}âœ… Final Answer:{RESET}")
                    print(final_answer)
                    return final_answer
                elif final_answer and iteration == 1:
                    messages.append({"role": "assistant", "content": output_cleaned})
                    messages.append({"role": "user", "content": "(ä½ å¿…é¡»å…ˆä½¿ç”¨å·¥å…·è·å–ä¿¡æ¯ï¼Œä¸èƒ½ç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚)"})
                    print(f"{YELLOW}âš ï¸ ç¬¬ä¸€è½®å¿…é¡»å…ˆè°ƒç”¨å·¥å…·ï¼Œè¯·ç»§ç»­...{RESET}")
                    continue
                else:
                    messages.append({"role": "assistant", "content": output_cleaned})
                    messages.append({"role": "user", "content": "(è¯·ç»§ç»­ï¼Œä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼šThought -> Action -> Action Input)"})
                    print(f"{YELLOW}âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Actionï¼Œæç¤ºæ¨¡å‹ç»§ç»­...{RESET}")
                    continue

            # æ˜¾ç¤ºæœ¬è½®æ€è€ƒ
            if not stream:
                thought = self._extract_thought(output_cleaned)
                if thought:
                    print(f"{CYAN}ğŸ’­ Thought:{RESET} {thought}")
                print(f"{CYAN}ğŸ¯ Action:{RESET} {action}")
                print(
                    f"{CYAN}ğŸ“¥ Action Input:{RESET} {json.dumps(action_input, ensure_ascii=False)}"
                )

            # æ‰§è¡Œå·¥å…·
            observation = execute_tool(action, action_input)
            print(
                f"{GRAY}ğŸ‘ï¸ Observation:{RESET} {observation[:200]}{'...' if len(observation) > 200 else ''}"
            )

            # è¿½åŠ åˆ° messages
            messages.append({"role": "assistant", "content": output_cleaned})
            messages.append({"role": "user", "content": f"Observation: {observation}"})

        return "é”™è¯¯ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°"

    # stop sequence åŠå…¶æ‰€æœ‰å¯èƒ½æˆªæ–­å½¢å¼çš„æ­£åˆ™
    # åŒ¹é…: \nO, \nOb, \nObs, \nObse, \nObser, \nObserv, ... \nObservation, \nObservation:
    STOP_PATTERN = r'\nOb(?:s(?:e(?:r(?:v(?:a(?:t(?:i(?:o(?:n?)?)?)?)?)?)?)?)?)?(?::\s*)?$'
    # ç”¨äºæ£€æµ‹ç¼“å†²åŒºæœ«å°¾æ˜¯å¦å¯èƒ½æ˜¯ stop sequence çš„å¼€å¤´
    STOP_PREFIX_RE = re.compile(r'\nOb[servaion]*$')

    def _handle_streaming(self, response) -> str:
        """æµå¼è¾“å‡º + è¿‡æ»¤ stop sequence"""
        collected = ""
        buffer = ""  # ç¼“å†²åŒºï¼šä¿ç•™æœ€åå¯èƒ½æ„æˆ stop sequence çš„å­—ç¬¦

        for chunk in response:
            if not chunk.choices[0].delta.content:
                continue

            content = chunk.choices[0].delta.content
            collected += content
            buffer += content

            # å½“ç¼“å†²åŒºè¶³å¤Ÿé•¿æ—¶ï¼Œå°è¯•è¾“å‡ºå®‰å…¨éƒ¨åˆ†
            while len(buffer) > 15:  # "\nObservation:" é•¿åº¦æ˜¯ 14
                # æ£€æŸ¥ç¼“å†²åŒºæœ«å°¾æ˜¯å¦å¯èƒ½æ˜¯ stop sequence çš„å¼€å¤´
                if self.STOP_PREFIX_RE.search(buffer):
                    # æœ«å°¾å¯èƒ½æ˜¯ stop sequenceï¼Œä¿ç•™ç¼“å†²åŒºï¼Œè·³å‡º
                    break
                else:
                    # æœ«å°¾å®‰å…¨ï¼Œè¾“å‡ºé™¤æœ€å 14 ä¸ªå­—ç¬¦å¤–çš„å†…å®¹
                    safe_len = len(buffer) - 14
                    print(buffer[:safe_len], end="", flush=True)
                    buffer = buffer[safe_len:]

        # æµç»“æŸï¼Œå¤„ç†ç¼“å†²åŒºå‰©ä½™å†…å®¹
        # æ¸…ç†å¯èƒ½çš„ stop sequence
        cleaned_buffer = re.sub(self.STOP_PATTERN, '', buffer)
        if cleaned_buffer:
            print(cleaned_buffer, end="", flush=True)
        print()  # æ¢è¡Œ

        # è®°å½•åŸå§‹æ•°æ®åˆ°æ—¥å¿—
        self.logger.debug(f"STREAMING RAW (repr): {repr(collected)}")

        # è¿”å›æ¸…ç†åçš„å®Œæ•´ç»“æœ
        return re.sub(self.STOP_PATTERN, '', collected).strip()


# ============================================
# æ¼”ç¤ºåœºæ™¯
# ============================================

DEMOS = {
    "1": {
        "name": "æ—…æ¸¸è§„åˆ’",
        "question": "å¸®æˆ‘è§„åˆ’æ˜å¤©çš„æ­å·ä¸€æ—¥æ¸¸ï¼Œéœ€è¦è€ƒè™‘å¤©æ°”æƒ…å†µã€‚",
        "stream": True,
    },
    "2": {
        "name": "æ•°å­¦è®¡ç®—",
        "question": "è®¡ç®— (123 + 456) * (789 - 654) çš„ç»“æœ",
        "stream": True,
    },
    "3": {
        "name": "å¤šæ­¥éª¤æŸ¥è¯¢",
        "question": "å‘Šè¯‰æˆ‘ç°åœ¨å‡ ç‚¹äº†ï¼Œç„¶åå¸®æˆ‘ç®—ä¸€ä¸‹ 9876 * 5432 ç­‰äºå¤šå°‘",
        "stream": True,
    },
}


def print_help():
    print("=" * 60)
    print("01 - ReAct Agent - çº¯æ–‡æœ¬ ReAct æ¨¡å¼")
    print("=" * 60)
    print()
    print("ç”¨æ³•: uv run python 01_react_agent.py <demo_id> [--model <model>]")
    print()
    print("å¯ç”¨çš„åœºæ™¯:")
    for demo_id, demo in DEMOS.items():
        print(f"  {demo_id}. {demo['name']}")
    print()
    print("æ”¯æŒçš„æ¨¡å‹ (-m):")
    print("  - glm / glm4.7: GLM-4.7 (é»˜è®¤)")
    print("  - ds / deepseek: DeepSeek Chat")
    print()
    print("ç¤ºä¾‹:")
    print("  uv run python 01_react_agent.py 1           # é»˜è®¤ GLM-4.7")
    print("  uv run python 01_react_agent.py 1 -m ds     # DeepSeek")
    print()


def main():
    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument("demo_id", nargs="?", default=None)
    parser.add_argument("-m", "--model", default="glm-4.7")
    parser.add_argument("-h", "--help", action="store_true")

    args = parser.parse_args()

    if args.help or args.demo_id is None:
        print_help()
        return

    if args.demo_id not in DEMOS:
        print(f"âŒ æœªçŸ¥çš„åœºæ™¯ ID: {args.demo_id}")
        print_help()
        return

    model_key = args.model.lower()
    provider = MODEL_ALIASES.get(model_key, "glm-4.7")

    demo = DEMOS[args.demo_id]
    print_section(f"ğŸ“Œ {demo['name']} [{provider}]")

    agent = ReActAgent(provider=provider)
    agent.run(demo["question"], stream=demo.get("stream", True))

    print("\n" + "-" * 60)
    print("âœ… å®Œæˆ")
    print("-" * 60)


if __name__ == "__main__":
    main()
