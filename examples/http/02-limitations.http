# ============================================
# 大模型局限性演示
# ============================================
# 说明：这些示例展示了大语言模型的固有局限性
# 目的：帮助理解 LLM 的工作原理和边界
# 模型：GLM-4.7（智谱 AI）、DeepSeek
# 注意：不同模型的局限性程度不同，以下测试基于 2026 年初的模型能力
# ============================================

@LOCALE = zh-CN
@response_language = You must respond in the locale specified by the LOCALE variable ({{LOCALE}}).All your responses should be in the language corresponding to this locale code.Do not use any other language regardless of the user's input language.

# 环境变量
@GLM_BASE_URL = https://open.bigmodel.cn/api/coding/paas/v4/chat/completions
@GLM_BEARER_TOKEN = Bearer {{$dotenv GLM_API_KEY}}

@STEPFUN_BASE_URL = https://api.stepfun.com/v1/chat/completions
@STEPFUN_BEARER_TOKEN = Bearer {{$dotenv STEPFUN_API_KEY}}

@DEEP_SEEK_BASE_URL = https://api.deepseek.com/chat/completions
@DEEP_SEEK_BEARER_TOKEN = Bearer {{$dotenv DEEPSEEK_API_KEY}}

# ============================================
# 1. 数学计算局限性
# ============================================

### [局限性 1.1] GLM-4.6 复杂小数计算 - 即使有推理也可能出错
# 说明：LLM 通过统计模式预测数字，不是真正的计算器
# 即使模型有内置推理（reasoning_content），复杂小数计算仍可能出错
# 正确答案（Python）：209528294431.6329
# GLM-4.6 错误答案：209543721753.0411（相差约 1540 万）
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "{{response_language}}"
    },
    {
      "role": "user",
      "content": "Calculate: 982717.1211 * 213213.23321 - 321312.777 / 1112.1121. Do NOT use any tools. Do NOT show reasoning. Just give the final number directly."
    }
  ],
  "max_tokens": 100,
  "model": "GLM-4.6",
  "stream": false,
  "temperature": 0
}

### [局限性 1.2] 解决方案：Function Calling + 计算器
# 说明：通过工具调用解决计算问题
# 原理：模型识别需要计算，调用外部计算器工具
# 预期：模型会调用 calculator 工具，返回精确结果
# 9876 × 5432 = 53646432
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个智能助手。当需要数学计算时，请使用 calculator 工具。"
    },
    {
      "role": "user",
      "content": "请计算：9876 × 5432 = ?"
    }
  ],
  "model": "GLM-4.7",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "calculator",
        "description": "执行数学计算表达式，返回精确结果",
        "parameters": {
          "type": "object",
          "properties": {
            "expression": {
              "type": "string",
              "description": "要计算的数学表达式，如 '9876 * 5432'"
            }
          },
          "required": ["expression"]
        }
      }
    }
  ],
  "stream": false,
  "temperature": 0
}

# ============================================
# 2. 知识截止日期局限性
# ============================================

### [局限性 2.1] 知识截止 - 2025 年后事件
# 说明：模型训练数据截止于特定日期，无法获取之后的信息
# 测试时间：2026-02-09
# 预期：模型会承认不知道，或基于旧信息推测
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个知识助手。如果不知道答案，请明确告知。"
    },
    {
      "role": "user",
      "content": "请问 2026 年 2 月发生了哪些重大科技新闻？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 2.2] 实时信息缺失 - 当前时间
# 说明：模型无法获取实时信息（时间、天气、股票等）
# 预期：模型可能编造一个时间，或承认无法获取
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个助手。"
    },
    {
      "role": "user",
      "content": "现在几点了？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 2.3] 解决方案：Function Calling + 实时 API
# 说明：通过工具调用获取实时信息
# 预期：模型调用 get_current_time 工具
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个助手。当需要获取实时信息时，请使用相应的工具。"
    },
    {
      "role": "user",
      "content": "现在几点了？"
    }
  ],
  "model": "GLM-4.7",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_time",
        "description": "获取当前时间（北京时间）",
        "parameters": {
          "type": "object",
          "properties": {},
          "required": []
        }
      }
    }
  ],
  "stream": false,
  "temperature": 0
}

### [局限性 2.4] 解决方案：StepFun Search API - 获取实时网络信息
# 说明：StepFun 提供内置的搜索 API，可以直接搜索互联网
# 官方文档：https://platform.stepfun.com/docs/zh/api-reference/Search/search
# 优势：针对重点场景优化站点权威性，适合深入研究
# 支持场景：programming（代码）、research（学术）、gov（政务）、business（商业）
POST https://api.stepfun.com/v1/search HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{STEPFUN_BEARER_TOKEN}}

{
  "query": "2026年2月 最新 AI 技术进展",
  "n": 5,
  "category": "research"
}

### [局限性 2.5] StepFun Search API - 代码编程场景
# 说明：搜索代码相关的技术文档和解决方案
POST https://api.stepfun.com/v1/search HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{STEPFUN_BEARER_TOKEN}}

{
  "query": "Python httpx streaming SSE server-sent events",
  "n": 3,
  "category": "programming"
}

# ============================================
# 3. 逻辑推理局限性
# ============================================

### [局限性 3.1] 严格逻辑推理 - 否定运算
# 说明：LLM 不具备基于形式逻辑的严格推理能力
# 问题：测试否定逻辑的理解
# 预期：可能出现逻辑错误
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个逻辑推理助手。请严格根据逻辑规则回答。"
    },
    {
      "role": "user",
      "content": "给定：\n1. 所有的猫都喜欢鱼\n2. Tom 不喜欢鱼\n\n请问：Tom 是不是猫？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 3.2] 多步推理 - 传递性关系
# 说明：测试模型处理多步传递性推理的能力
# 正确答案：C 比 A 高（A<B, B<C => A<C）
# 预期：可能在多步推理中出错
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个逻辑推理助手。"
    },
    {
      "role": "user",
      "content": "给定：\n1. A 比 B 矮\n2. B 比 C 矮\n3. C 比 D 矮\n4. D 比 E 矮\n\n请问：C 和 A 谁更高？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 3.3] 经典逻辑陷阱 - 理发师悖论
# 说明：测试模型处理悖论的能力
# 问题：自指悖论（Russell 悖论的通俗版）
# 预期：可能给出矛盾的回答，或回避问题
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个逻辑推理助手。"
    },
    {
      "role": "user",
      "content": "在一个村庄里，有一个理发师。他的规则是：\n- 他给所有不给自己刮胡子的人刮胡子\n- 他不给给自己刮胡子的人刮胡子\n\n请问：这个理发师给自己刮胡子吗？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

# ============================================
# 4. 幻觉问题
# ============================================

### [局限性 4.1] 事实混淆 - 经典案例
# 说明：模型可能混淆不同来源的知识，产生"幻觉"
# 经典案例："林黛玉倒拔垂杨柳"（混淆《红楼梦》和《水浒传》）
# 预期：可能会混淆角色和情节
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个文学知识助手。"
    },
    {
      "role": "user",
      "content": "请问《红楼梦》中是谁倒拔了垂杨柳？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 4.2] 编造不存在的 API - 技术幻觉
# 说明：模型可能编造不存在的函数、API 或技术细节
# 预期：可能会"创造"一个听起来合理但不存在的 API
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个技术专家。如果不确定，请明确说明。"
    },
    {
      "role": "user",
      "content": "请问 Python 的 os 模块中有一个叫 os.get_all_processes() 的函数吗？如果有，请说明它的用法。"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 4.2b] GLM-4.6 事实混淆 - 文学幻觉
# 说明：GLM-4.6 会编造不存在的故事情节
# 陷阱问题："《红楼梦》中谁倒拔了垂杨柳？"
# 正确答案：这是《水浒传》中鲁智深的故事，不是《红楼梦》
# GLM-4.6 错误回答：编造了"贾宝玉命令晴雯拔柳树"的情节
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "{{response_language}}"
    },
    {
      "role": "user",
      "content": "In the novel Dream of the Red Chamber, who uprooted the willow tree? Answer briefly."
    }
  ],
  "model": "GLM-4.6",
  "stream": false,
  "temperature": 0
}

### [局限性 4.2c] GLM-4.6 训练数据时效性 - Python 3.14 新 API
# 说明：模型可能不知道训练数据截止后的新 API
# Python 3.14（2025年10月发布）新增了 compression.zstd 模块
# 预期：模型可能承认不知道，或编造一个看起来合理的用法
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "{{response_language}} 直接回答，不用推理"
    },
    {
      "role": "user",
      "content": "Python 3.14 introduced a new compression.zstd module. Please explain how to use compression.zstd.compress() and show an example."
    }
  ],
  "model": "GLM-4.6",
  "stream": false,
  "temperature": 0
}

### [局限性 4.3] 虚假引用 - 学术幻觉
# 说明：模型可能编造不存在的论文、作者或引用
# 预期：可能会"创造"一个听起来专业的虚假引用
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个学术研究助手。"
    },
    {
      "role": "user",
      "content": "请推荐 3 篇关于'量子纠缠在区块链中的应用'的权威论文，包括作者、标题和发表年份。"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [局限性 4.4] 对比测试 - 高 temperature 增加幻觉风险
# 说明：temperature 越高，模型越"创造性"，幻觉风险也越高
# 预期：temperature=1.5 可能产生更多不可靠的内容
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个技术专家。"
    },
    {
      "role": "user",
      "content": "请介绍一下 JavaScript 中的 Array.prototype.superMap() 方法。"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 1.5
}

# ============================================
# 5. 上下文长度局限性
# ============================================

### [局限性 5.1] 长文本记忆 - 首尾效应
# 说明：模型对上下文的开头和结尾记忆较好，中间部分容易遗忘
# 测试：提供一个长列表，询问中间的内容
# 答案：济南
# 预期：可能遗忘或混淆中间部分的信息
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个助手，请根据给定信息回答问题。"
    },
    {
      "role": "user",
      "content": "以下是一个城市列表：\n北京、上海、广州、深圳、杭州、南京、武汉、成都、重庆、西安、天津、苏州、长沙、郑州、济南、青岛、大连、沈阳、哈尔滨、长春、厦门、福州、昆明、贵阳、南宁、海口、兰州、银川、西宁、乌鲁木齐。\n\n请问：第 15 个城市是哪个？"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

# ============================================
# 6. GLM-4.6 Function Calling 演示
# ============================================

### [Function Calling 6.1] GLM-4.6 非流式 - 多工具调用
# 说明：GLM-4.6 支持同时调用多个工具
# 工具：calculator（计算器）、get_current_time（获取时间）
# 预期：模型会依次调用两个工具，然后整合结果
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个智能助手。当需要数学计算时使用 calculator 工具，需要获取时间时使用 get_current_time 工具。"
    },
    {
      "role": "user",
      "content": "请帮我计算 (123 + 456) * 789 / 10 的结果，然后告诉我现在几点了。"
    }
  ],
  "model": "GLM-4.6",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "calculator",
        "description": "执行数学计算表达式，返回精确结果。支持 +、-、*、/ 等运算符。",
        "parameters": {
          "type": "object",
          "properties": {
            "expression": {
              "type": "string",
              "description": "要计算的数学表达式，如 '9876 * 5432'"
            }
          },
          "required": ["expression"]
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "get_current_time",
        "description": "获取当前时间（北京时间）",
        "parameters": {
          "type": "object",
          "properties": {},
          "required": []
        }
      }
    }
  ],
  "stream": false,
  "temperature": 0
}

### [Function Calling 6.2] GLM-4.6 流式 - 多工具调用
# 说明：GLM-4.6 流式输出，支持 Function Calling
# 流程：模型会逐步输出思考过程，然后调用工具
# 注意：流式模式下 tool_calls 是增量传输的，需要收集完整后再执行
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个智能助手。当需要数学计算时使用 calculator 工具，需要获取时间时使用 get_current_time 工具。"
    },
    {
      "role": "user",
      "content": "计算 9876 * 5432，告诉我结果，还有现在几点。"
    }
  ],
  "model": "GLM-4.6",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "calculator",
        "description": "执行数学计算表达式，返回精确结果",
        "parameters": {
          "type": "object",
          "properties": {
            "expression": {
              "type": "string",
              "description": "要计算的数学表达式"
            }
          },
          "required": ["expression"]
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "get_current_time",
        "description": "获取当前时间（北京时间）",
        "parameters": {
          "type": "object",
          "properties": {},
          "required": []
        }
      }
    }
  ],
  "stream": true,
  "temperature": 0
}

### [Function Calling 6.3] GLM-4.6 复杂计算 - 解决数学局限性
# 说明：通过工具调用解决 GLM-4.6 的复杂小数计算问题
# 对比 [局限性 1.1]，这次使用工具获得精确结果
# 正确答案：209528294431.6329（约 2095.28 亿）
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个数学助手。请使用 calculator 工具进行精确计算，不要自己计算。"
    },
    {
      "role": "user",
      "content": "请计算：982717.1211 * 213213.23321 - 321312.777 / 1112.1121"
    }
  ],
  "model": "GLM-4.6",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "calculator",
        "description": "执行数学计算表达式，返回精确结果",
        "parameters": {
          "type": "object",
          "properties": {
            "expression": {
              "type": "string",
              "description": "要计算的数学表达式"
            }
          },
          "required": ["expression"]
        }
      }
    }
  ],
  "stream": false,
  "temperature": 0
}

# ============================================
# 7. 模型对比 - GLM vs DeepSeek
# ============================================

### [对比 7.1] GLM-4.7 - 大数乘法
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "你是一个数学助手。请直接给出计算结果，不需要解释过程。不要推理，不要思考，直接给出答案"
    },
    {
      "role": "user",
      "content": "请计算：9876 × 5432，只给出数字结果。"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### [对比 7.2] DeepSeek - 大数乘法
# 9876 × 5432 = 53646432
POST {{DEEP_SEEK_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{DEEP_SEEK_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "user",
      "content": "请计算：9876 × 5432，只给出数字结果。"
    }
  ],
  "model": "deepseek-chat",
  "stream": false,
  "temperature": 0
}

# ============================================
# 总结
# ============================================
#
# 大模型的核心局限性：
# 1. 数学计算：基于概率预测，不是真正的计算器 → 解决：Function Calling + 计算器工具
#    - 简单整数运算：现代模型（GLM-4.7）通常正确
#    - 复杂小数运算：即使有内置推理，仍可能出错（如 GLM-4.6 测试）
# 2. 知识截止：无法获取训练后的新信息 → 解决：RAG、Web Search、实时 API
# 3. 逻辑推理：缺乏形式逻辑的严格推理能力 → 解决：Chain-of-Thought、外部推理引擎
# 4. 幻觉问题：可能编造不存在的事实 → 解决：验证机制、低 temperature、Few-Shot 示例
#    - 事实混淆：GLM-4.6 编造"贾宝玉拔柳树"情节
#    - 技术幻觉：可能编造不存在的 API 或用法
# 5. 上下文限制：记忆容量有限，长文本处理能力受限 → 解决：分块处理、摘要、向量检索
#
# 模型差异说明（2026 年初测试）：
# | 模型 | 数学计算 | 幻觉控制 | 内置推理 |
# |------|---------|---------|---------|
# | GLM-4.7 | ❌ 复杂出错 | ❌ 有幻觉 | ✅ 有 |
# | DeepSeek | ✅ 较好 | 较好 | 可选 |
#
# 关键启示：
# - LLM 是"理解和生成语言的专家"，而非"知识库"或"计算器"
# - 应该将 LLM 作为"协调者"（Agent），调用专业工具完成具体任务
# - Function Calling 是弥补 LLM 局限性的核心技术
# - 不同模型的局限性程度不同，需要根据实际场景选择
#
# 参考资料：
# - 大模型的科学解释和逻辑增强: https://www.caa.org.cn/article/345/5045.html
# - 大模型幻觉及其价值风险: http://www.news.cn/tech/20250411/250a24bfd95c4551869630f53e9584d6/c.html
# - 智谱 AI 官方文档: https://open.bigmodel.cn/dev/api
# - DeepSeek 官方文档: https://platform.deepseek.com/api-docs/
# ============================================
