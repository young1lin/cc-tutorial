# DeepSeek
@DEEP_SEEK_BASE_URL = https://api.deepseek.com/chat/completions
@DEEP_SEEK_BEARER_TOKEN = Bearer {{$dotenv DEEPSEEK_API_KEY}}

# 智谱 GLM
@GLM_BASE_URL = https://open.bigmodel.cn/api/coding/paas/v4/chat/completions
@GLM_BEARER_TOKEN = Bearer {{$dotenv GLM_API_KEY}}

# StepFun
@STEPFUN_BASE_URL = https://api.stepfun.com/v1/chat/completions
@STEPFUN_BEARER_TOKEN = Bearer {{$dotenv STEPFUN_API_KEY}}

# 通用变量
# 日语 ja-JP 韩文 ko-KR 简体中文 zh-CN 繁体中文 zh-TW 英文 en-US 印尼语 id-ID
@LOCALE = zh-CN
@main_prompt = You are an intelligent customer service agent named Alice. Your main role is to help users answer their questions.
@response_language = You must respond in the locale specified by the LOCALE variable ({{LOCALE}}).All your responses should be in the language corresponding to this locale code.Do not use any other language regardless of the user's input language.


### ⭐ Hello World —— 最裸的 API 请求
# 无 system prompt，无参数调优，就一条消息。
# 观察返回的 JSON 结构：choices[0].message.content 是回复正文，usage 是 token 用量。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "Hello, who are you?",
      "role": "user"
    }
  ],
  "model": "GLM-4.7",
  "stream": false
}

### ⭐ System Prompt —— 给模型一个角色
# 同样的问题，加上 system prompt 后模型会以 Alice 的身份回答。
# 对比上面那个请求，感受 system prompt 的作用。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}}",
      "role": "system"
    },
    {
      "content": "你好，你是谁？",
      "role": "user"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### ⭐ 流式输出 (Streaming)
# stream: true 时，响应是 SSE 数据帧（text/event-stream）。
# 每一行 data: {...} 包含一个增量 token，最后一帧 finish_reason 为 "stop"。
POST {{DEEP_SEEK_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: text/event-stream
Authorization: {{DEEP_SEEK_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}}",
      "role": "system"
    },
    {
      "content": "Hello, who are you?",
      "role": "user"
    }
  ],
  "model": "deepseek-chat",
  "stream": true,
  "temperature": 0
}

### ⭐ 字数不等于 Token
# max_tokens: 50 限制输出。注意：回复会被截断，因为 50 个 token 不等于 50 个字。
# 中文一个字通常 1 个 token，英文一个词通常 1 个 token，代码标点各不同。
POST {{DEEP_SEEK_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{DEEP_SEEK_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}}",
      "role": "system"
    },
    {
      "content": "Tell me a short story above 100 words.",
      "role": "user"
    }
  ],
  "max_tokens": 50,
  "model": "deepseek-chat",
  "stream": false,
  "temperature": 1
}

### ⭐⭐ 强制要求用户的返回指定语言
# system prompt 里加上语言指令，无论用户用什么语言提问，模型都用 LOCALE 对应语言回复。
# 这是多语言客服的基础做法。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}} {{response_language}}",
      "role": "system"
    },
    {
      "content": "你好，你是谁？",
      "role": "user"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### ⭐⭐ 多轮对话 (Regular conversation)
# messages 数组里追加历史消息，模型才能"记住"之前说了什么。
# LLM 本身无状态，上下文靠客户端每次把完整历史传过去。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}} 当前公司主营业务为量化交易. ",
      "role": "system"
    },
    {
      "content": "你好，你是谁？",
      "role": "user"
    },
    {
      "content": "你好，我是Alice，你的智能客服助手。今天我能帮你什么？",
      "role": "assistant"
    },
    {
      "content": "我想咨询你们公司的业务。",
      "role": "user"
    }
  ],
  "model": "GLM-4.7",
  "stream": false,
  "temperature": 0
}

### ⭐⭐⭐ Function calling conversation
# 模型不会真的调用工具——它输出一段结构化的 tool_calls JSON，由外部程序执行。
# 观察 finish_reason: "tool_calls" 和 message.tool_calls 字段。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "content": "{{main_prompt}}",
      "role": "system"
    },
    {
      "content": "请查询杭州的天气",
      "role": "user"
    }
  ],
  "model": "GLM-4.7",
  "tools": [
    {
      "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get weather information for a location.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The name of the city to get weather for. Only support low case location name, like beijing, shanghai, hangzhou, newyork"
                    }
                },
                "required": ["location"]
            }
        }
    }
  ],
  "stream": false,
  "temperature": 0
}

### ⭐⭐⭐ Function calling conversation with tool call
# 上一步模型输出了 tool_calls，这里把工具执行结果以 role: "tool" 消息传回。
# 模型再发一次请求，得到最终回复。这就是 Function Calling 的完整两轮交互。
POST {{GLM_BASE_URL}} HTTP/1.1
Content-Type: application/json
Accept: application/json
Authorization: {{GLM_BEARER_TOKEN}}

{
  "messages": [
    {
      "role": "system",
      "content": "{{main_prompt}}"
    },
    {
      "role": "user",
      "content": "请查询杭州的天气"
    },
    {
      "role": "assistant",
      "content": "我马上查询杭州的天气",
      "tool_calls": [
        {
          "index": 0,
          "id": "call_0_c9f112b0-766e-48ee-8b7d-a70c14f16b43",
          "type": "function",
          "function": {
            "name": "get_weather",
            "arguments": "{\"location\": \"hangzhou\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "tool_call_id": "call_0_c9f112b0-766e-48ee-8b7d-a70c14f16b43",
      "content": "Sunny, 29°C"
    }
  ],
  "model": "GLM-4.7",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get weather information for a location.",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The name of the city to get weather for. Only support low case location name, like beijing, shanghai, hangzhou, newyork"
            }
          },
          "required": [
            "location"
          ]
        }
      }
    }
  ],
  "stream": false,
  "temperature": 0
}
